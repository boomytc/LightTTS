# VoxCPM WebSocket 流式语音合成接口说明

## 服务信息

- **服务类型**: WebSocket 流式语音合成服务
- **默认地址**: `ws://127.0.0.1:8771`
- **协议**: WebSocket
- **音频格式**: WAV (16000Hz)

## 启动服务

```bash
# 使用默认参数启动
python serve/voxcpm/voxcpm_ws.py

# 自定义参数启动
python serve/voxcpm/voxcpm_ws.py \
    --model-dir models/VoxCPM-0.5B \
    --zipenhancer-model-id models/speech_zipenhancer_ans_multiloss_16k_base \
    --device cuda \
    --host 0.0.0.0 \
    --port 8771
```

### 启动参数

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `--model-dir` | string | `models/VoxCPM-0.5B` | VoxCPM 模型目录路径 |
| `--zipenhancer-model-id` | string | `models/speech_zipenhancer_ans_multiloss_16k_base` | ZipEnhancer 降噪模型路径 |
| `--device` | string | `cuda` | 运行设备（cuda 或 cpu） |
| `--host` | string | `0.0.0.0` | 服务器绑定地址 |
| `--port` | int | `8771` | 服务器端口号 |

## 连接流程

### 1. 建立 WebSocket 连接

```python
import websockets
import asyncio

async def connect():
    uri = "ws://127.0.0.1:8771"
    async with websockets.connect(uri, max_size=None) as websocket:
        # 接收欢迎消息
        welcome = await websocket.recv()
        print(welcome)  # JSON 格式的欢迎消息
        
        # 后续操作...
```

### 2. 接收欢迎消息

连接成功后，服务器会发送欢迎消息（文本格式，JSON）：

```json
{
    "status": "success",
    "message": "已连接到 VoxCPM WebSocket（流式）",
    "usage": "发送 {\"type\":\"tts_stream\", \"text\":\"...\", \"prompt_text\":\"...\", ...} 开始流式合成"
}
```

## 请求接口

### 请求格式

客户端发送 JSON 文本消息，包含以下字段：

```json
{
    "type": "tts_stream",
    "text": "待合成的文本内容",
    "prompt_audio": "asset/zero_shot_prompt.wav",
    "prompt_text": "希望你以后能够做得比我还好哟。",
    "cfg_value": 2.0,
    "inference_timesteps": 10,
    "normalize": true,
    "denoise": true,
    "retry_badcase": false
}
```

### 请求参数说明

#### 必填参数

| 参数 | 类型 | 必填 | 默认值 | 说明 |
|------|------|------|--------|------|
| `type` | string | ✅ | - | 请求类型，固定为 `"tts_stream"` |
| `text` | string | ✅ | - | 待合成的文本内容 |

#### 可选参数

| 参数 | 类型 | 必填 | 默认值 | 说明 |
|------|------|------|--------|------|
| `prompt_audio` | string | ❌ | `null` | 参考音频文件路径（零样本克隆） |
| `prompt_text` | string | ❌ | `null` | 参考音频对应的文本（与 `prompt_audio` 配套使用） |
| `cfg_value` | float | ❌ | `2.0` | CFG 引导尺度（1.0-3.0，值越高遵循越好） |
| `inference_timesteps` | int | ❌ | `10` | 推理时间步数（4-30，值越高质量越好但速度越慢） |
| `normalize` | bool | ❌ | `true` | 是否启用文本标准化 |
| `denoise` | bool | ❌ | `true` | 是否启用降噪处理 |
| `retry_badcase` | bool | ❌ | `false` | 是否启用糟糕情况重试 |
| `retry_max_times` | int | ❌ | `3` | 最大重试次数（当 `retry_badcase=true` 时） |
| `retry_ratio_threshold` | float | ❌ | `6.0` | 糟糕情况检测阈值（3.0-10.0） |

### 参数详细说明

#### 零样本克隆

- 提供 `prompt_audio` 和 `prompt_text` 可以克隆参考音频的音色
- 如果不提供，将使用默认音色合成

#### CFG 值 (cfg_value)

- **范围**: 1.0 - 3.0
- **推荐**: 2.0
- **说明**: 
  - 值越高：对提示遵循越好，但可能降低自然度
  - 值越低：更自然，但可能偏离提示

#### 推理时间步数 (inference_timesteps)

- **范围**: 4 - 30
- **推荐**: 10
- **说明**:
  - 值越高：质量越好，但速度越慢
  - 值越低：速度快，但质量可能下降

#### 糟糕情况重试 (retry_badcase)

- 自动检测生成质量不佳的情况并重试
- 通过音频长度与文本长度的比率判断
- `retry_ratio_threshold` 控制判断阈值

### 请求示例

#### 基础合成（默认音色）

```json
{
    "type": "tts_stream",
    "text": "八百标兵奔北坡，炮兵并排北边跑。",
    "cfg_value": 2.0,
    "inference_timesteps": 10,
    "normalize": true,
    "denoise": true
}
```

#### 零样本克隆

```json
{
    "type": "tts_stream",
    "text": "今天天气真不错啊！",
    "prompt_audio": "asset/zero_shot_prompt.wav",
    "prompt_text": "希望你以后能够做得比我还好哟。",
    "cfg_value": 2.0,
    "inference_timesteps": 10,
    "normalize": true,
    "denoise": true
}
```

#### 高质量模式

```json
{
    "type": "tts_stream",
    "text": "这是一段需要高质量合成的文本。",
    "prompt_audio": "asset/zero_shot_prompt.wav",
    "prompt_text": "希望你以后能够做得比我还好哟。",
    "cfg_value": 2.5,
    "inference_timesteps": 20,
    "normalize": true,
    "denoise": true,
    "retry_badcase": true,
    "retry_max_times": 5,
    "retry_ratio_threshold": 5.0
}
```

#### 快速模式

```json
{
    "type": "tts_stream",
    "text": "快速生成的文本内容。",
    "cfg_value": 1.8,
    "inference_timesteps": 6,
    "normalize": true,
    "denoise": false
}
```

## 响应接口

### 响应流程

服务器会发送以下消息：

1. **音频数据**（二进制消息，一次性发送）
2. **结束标记**（文本消息，JSON）

### 响应消息类型

#### 1. 音频数据

- **格式**: 二进制数据
- **内容**: WAV 格式的完整音频数据
- **采样率**: 16000Hz
- **数量**: 1 次（完整音频）

接收示例：

```python
async for msg in websocket:
    if isinstance(msg, bytes):
        # 二进制音频数据（完整）
        audio_bytes = msg
        # 可以直接保存或播放
```

#### 2. 结束标记

```json
{
    "type": "end"
}
```

#### 3. 错误消息

```json
{
    "status": "error",
    "message": "错误描述信息"
}
```

## 完整使用示例

### Python 客户端

```python
import asyncio
import json
import websockets
import io
import torchaudio

async def synthesize(text, use_voice_cloning=True):
    uri = "ws://127.0.0.1:8771"
    
    async with websockets.connect(uri, max_size=None) as ws:
        # 1. 接收欢迎消息
        welcome = await ws.recv()
        print("连接成功:", json.loads(welcome)["message"])
        
        # 2. 发送合成请求
        request = {
            "type": "tts_stream",
            "text": text,
            "cfg_value": 2.0,
            "inference_timesteps": 10,
            "normalize": True,
            "denoise": True,
            "retry_badcase": False
        }
        
        # 如果使用零样本克隆
        if use_voice_cloning:
            request["prompt_audio"] = "asset/zero_shot_prompt.wav"
            request["prompt_text"] = "希望你以后能够做得比我还好哟。"
        
        await ws.send(json.dumps(request, ensure_ascii=False))
        
        # 3. 接收音频
        audio_data = None
        async for msg in ws:
            if isinstance(msg, bytes):
                # 音频数据
                audio_data = msg
                print(f"收到音频数据 ({len(msg)} 字节)")
            else:
                # 控制消息
                data = json.loads(msg)
                if data.get("type") == "end":
                    print("生成完成")
                    break
                elif data.get("status") == "error":
                    print("错误:", data.get("message"))
                    break
        
        return audio_data

# 运行示例
if __name__ == "__main__":
    asyncio.run(synthesize("八百标兵奔北坡，炮兵并排北边跑。"))
```

### JavaScript 客户端

```javascript
const ws = new WebSocket('ws://127.0.0.1:8771');

ws.onopen = () => {
    console.log('连接成功');
};

ws.onmessage = async (event) => {
    if (event.data instanceof Blob) {
        // 二进制音频数据
        const audioBlob = event.data;
        console.log('收到完整音频');
        // 可以播放或保存
    } else {
        // 文本消息
        const data = JSON.parse(event.data);
        console.log('收到消息:', data);
        
        if (data.status === "success") {
            // 欢迎消息，发送请求
            const request = {
                type: "tts_stream",
                text: "八百标兵奔北坡，炮兵并排北边跑。",
                prompt_audio: "asset/zero_shot_prompt.wav",
                prompt_text: "希望你以后能够做得比我还好哟。",
                cfg_value: 2.0,
                inference_timesteps: 10,
                normalize: true,
                denoise: true,
                retry_badcase: false
            };
            ws.send(JSON.stringify(request));
        } else if (data.type === "end") {
            console.log('生成完成');
            ws.close();
        }
    }
};
```

## 错误处理

### 常见错误

| 错误信息 | 原因 | 解决方法 |
|---------|------|---------|
| `缺少有效的 text` | 未提供文本或文本为空 | 确保 `text` 字段非空 |
| `使用参考音频时，请提供对应的参考文本` | 只提供了 `prompt_audio` 未提供 `prompt_text` | 同时提供两个参数或都不提供 |
| `模型加载失败` | 模型路径错误或权限问题 | 检查模型路径和权限 |
| `推理失败` | 参数超出范围或模型错误 | 检查参数范围是否正确 |
| `连接失败` | 服务器未启动或地址错误 | 确认服务器已启动且地址正确 |

## 性能参考

- **生成延迟**: ~3-8 秒（取决于 `inference_timesteps` 和文本长度）
- **音频质量**: 16000Hz，高质量语音合成
- **总耗时**: 约为音频时长的 1.5-3 倍（实时率 RTF 1.5-3）
- **质量因素**:
  - `inference_timesteps=10`: 标准质量，速度较快
  - `inference_timesteps=20`: 高质量，速度较慢
  - `denoise=true`: 提升音质，增加少量耗时

## 注意事项

1. **音频路径**: `prompt_audio` 必须是服务器可访问的路径
2. **参考文本**: 使用零样本克隆时，`prompt_text` 必须与 `prompt_audio` 内容一致
3. **参数调优**: 
   - 快速场景：`inference_timesteps=6-8`, `cfg_value=1.8`
   - 标准场景：`inference_timesteps=10`, `cfg_value=2.0`
   - 高质量场景：`inference_timesteps=15-20`, `cfg_value=2.5`
4. **文本标准化**: 建议保持 `normalize=true`，可处理数字、符号等
5. **降噪处理**: `denoise=true` 可提升音质，但会增加少量耗时
6. **并发**: 服务器支持多客户端并发连接
7. **超时**: 高质量模式建议设置 90 秒以上超时
