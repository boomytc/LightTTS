#!/usr/bin/env python3
"""
VoxCPM WebSocket è¯­éŸ³åˆæˆæœåŠ¡å™¨ï¼ˆæµå¼ï¼‰
- å®¢æˆ·ç«¯å‘é€ JSONï¼š{"type":"tts_stream", "text":"...", "prompt_text":"...", ...}
- æœåŠ¡ç«¯å®æ—¶ç”ŸæˆéŸ³é¢‘å¹¶é€æ®µä»¥"äºŒè¿›åˆ¶å¸§"å‘å›å®¢æˆ·ç«¯
- åˆæˆç»“æŸåï¼Œå‘é€ JSON æ–‡æœ¬æ¶ˆæ¯ï¼š{"type":"end"}
"""

import asyncio
import json
import os
import sys
import io
import websockets
import torch
import soundfile as sf
import numpy as np

current_dir = os.path.dirname(__file__)
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, project_root)

os.environ["TOKENIZERS_PARALLELISM"] = "false"

if torch.cuda.is_available():
    torch.set_float32_matmul_precision("high")

try:
    import torch._dynamo as dynamo
    dynamo.config.suppress_errors = True  # type: ignore
except Exception:
    pass

from voxcpm.core import VoxCPM
from voxcpm.model.voxcpm import VoxCPMModel


def _disable_optimize(self: VoxCPMModel):
    """ç¦ç”¨åœ¨æŸäº› CUDA è®¾ç½®ä¸‹å¤±è´¥çš„ torch.compile ä¼˜åŒ–ã€‚"""
    self.base_lm.forward_step = self.base_lm.forward_step
    self.residual_lm.forward_step = self.residual_lm.forward_step
    self.feat_encoder_step = self.feat_encoder
    self.feat_decoder.estimator = self.feat_decoder.estimator
    return self


VoxCPMModel.optimize = _disable_optimize


class VoxCPMWebSocketServer:
    def __init__(
        self,
        model_dir: str = "models/VoxCPM-0.5B",
        zipenhancer_model_id: str = "models/speech_zipenhancer_ans_multiloss_16k_base",
        device: str = "cuda",
        host: str = "0.0.0.0",
        port: int = 8771,
    ):
        self.model_dir = model_dir
        self.zipenhancer_model_id = zipenhancer_model_id
        self.device = device
        self.host = host
        self.port = port
        self.model = None

    def load_model(self):
        """åŠ è½½æ¨¡å‹"""
        if self.model is None:
            print("æ­£åœ¨åŠ è½½ VoxCPM æ¨¡å‹...")
            self.model = VoxCPM.from_pretrained(
                hf_model_id=self.model_dir,
                load_denoiser=False,  # ç»Ÿä¸€ä½¿ç”¨å¤–éƒ¨ zipenhancer
                zipenhancer_model_id=self.zipenhancer_model_id,
                local_files_only=True,
                device=self.device,
            )
            print(f"âœ… VoxCPM æ¨¡å‹åŠ è½½å®Œæˆ [è®¾å¤‡: {self.device}]")
        return self.model

    async def websocket_handler(self, websocket):
        """å¤„ç† WebSocket è¿æ¥"""
        # å‘é€æ¬¢è¿æ¶ˆæ¯
        welcome_msg = {
            "status": "success",
            "message": "å·²è¿æ¥åˆ° VoxCPM WebSocketï¼ˆæµå¼ï¼‰",
            "usage": "å‘é€ {\"type\":\"tts_stream\", \"text\":\"...\", \"prompt_text\":\"...\", ...} å¼€å§‹æµå¼åˆæˆ",
        }
        await websocket.send(json.dumps(welcome_msg, ensure_ascii=False))

        try:
            # æ¥æ”¶å®¢æˆ·ç«¯è¯·æ±‚
            raw_msg = await websocket.recv()
            try:
                data = json.loads(raw_msg)
            except Exception:
                await websocket.send(
                    json.dumps({"status": "error", "message": "æ— æ•ˆçš„JSON"}, ensure_ascii=False)
                )
                return

            if data.get("type") != "tts_stream":
                await websocket.send(
                    json.dumps({"status": "error", "message": "ä»…æ”¯æŒ tts_stream"}, ensure_ascii=False)
                )
                return

            # è§£æå‚æ•°
            text = data.get("text")
            prompt_wav_path = data.get("prompt_audio")
            prompt_text = data.get("prompt_text", "")
            cfg_value = data.get("cfg_value", 2.0)
            inference_timesteps = data.get("inference_timesteps", 10)
            normalize = data.get("normalize", True)
            denoise = data.get("denoise", True)
            retry_badcase = data.get("retry_badcase", False)
            retry_max_times = data.get("retry_max_times", 3)
            retry_ratio_threshold = data.get("retry_ratio_threshold", 6.0)

            # å‚æ•°éªŒè¯
            if not text or not isinstance(text, str):
                await websocket.send(
                    json.dumps({"status": "error", "message": "ç¼ºå°‘æœ‰æ•ˆçš„ text"}, ensure_ascii=False)
                )
                return

            if prompt_wav_path and not prompt_text:
                await websocket.send(
                    json.dumps({"status": "error", "message": "ä½¿ç”¨å‚è€ƒéŸ³é¢‘æ—¶ï¼Œè¯·æä¾›å¯¹åº”çš„ prompt_text"}, ensure_ascii=False)
                )
                return

            # åŠ è½½æ¨¡å‹
            try:
                model = self.load_model()
            except Exception as e:
                await websocket.send(
                    json.dumps({"status": "error", "message": f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"}, ensure_ascii=False)
                )
                return

            # æ‰§è¡Œæ¨ç†
            try:
                wav = model.generate(
                    text=text,
                    prompt_wav_path=prompt_wav_path,  # type: ignore
                    prompt_text=prompt_text,  # type: ignore
                    cfg_value=float(cfg_value),
                    inference_timesteps=int(inference_timesteps),
                    normalize=normalize,
                    denoise=denoise,
                    retry_badcase=retry_badcase,
                    retry_badcase_max_times=int(retry_max_times),
                    retry_badcase_ratio_threshold=float(retry_ratio_threshold),
                )
            except Exception as e:
                await websocket.send(
                    json.dumps({"status": "error", "message": f"æ¨ç†å¤±è´¥: {str(e)}"}, ensure_ascii=False)
                )
                return

            # å°†éŸ³é¢‘è½¬æ¢ä¸º WAV æ ¼å¼çš„å­—èŠ‚æµ
            buffer = io.BytesIO()
            sf.write(buffer, wav, 16000, format="wav")
            buffer.seek(0)
            audio_bytes = buffer.read()

            # å‘é€äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®
            await websocket.send(audio_bytes)

            # åˆæˆå®Œæˆï¼Œå‘é€ç»“æŸæ ‡è®°
            await websocket.send(json.dumps({"type": "end"}, ensure_ascii=False))

        except websockets.exceptions.ConnectionClosed:
            # å®¢æˆ·ç«¯ä¸­æ–­è¿æ¥
            return
        except Exception as e:
            # å‘ç”Ÿé”™è¯¯æ—¶è¿”å›é”™è¯¯æ¶ˆæ¯
            try:
                await websocket.send(
                    json.dumps({"status": "error", "message": f"æœåŠ¡å™¨é”™è¯¯: {str(e)}"}, ensure_ascii=False)
                )
            except Exception:
                pass

    async def start_server(self):
        """å¯åŠ¨ WebSocket æœåŠ¡å™¨"""
        print(f"å¯åŠ¨ VoxCPM æµå¼ WebSocket æœåŠ¡å™¨: ws://{self.host}:{self.port}")
        
        # é¢„åŠ è½½æ¨¡å‹
        self.load_model()
        
        print(f"\nğŸš€ æœåŠ¡å™¨å·²å°±ç»ªï¼Œç­‰å¾…å®¢æˆ·ç«¯è¿æ¥...")
        async with websockets.serve(self.websocket_handler, self.host, self.port, max_size=None):
            await asyncio.Future()  # è¿è¡Œç›´åˆ°æ‰‹åŠ¨åœæ­¢


async def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description="VoxCPM WebSocket æµå¼è¯­éŸ³åˆæˆæœåŠ¡",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument(
        "--model-dir",
        type=str,
        default="models/VoxCPM-0.5B",
        help="VoxCPM æ¨¡å‹ç›®å½•è·¯å¾„"
    )
    parser.add_argument(
        "--zipenhancer-model-id",
        type=str,
        default="models/speech_zipenhancer_ans_multiloss_16k_base",
        help="ZipEnhancer é™å™ªæ¨¡å‹è·¯å¾„"
    )
    parser.add_argument(
        "--device",
        type=str,
        default="cuda" if torch.cuda.is_available() else "cpu",
        choices=["cuda", "cpu"],
        help="è¿è¡Œè®¾å¤‡ï¼ˆcuda æˆ– cpuï¼‰"
    )
    parser.add_argument(
        "--host",
        type=str,
        default="0.0.0.0",
        help="æœåŠ¡å™¨ç»‘å®šåœ°å€"
    )
    parser.add_argument(
        "--port",
        type=int,
        default=8771,
        help="æœåŠ¡å™¨ç«¯å£å·"
    )
    
    args = parser.parse_args()
    
    server = VoxCPMWebSocketServer(
        model_dir=args.model_dir,
        zipenhancer_model_id=args.zipenhancer_model_id,
        device=args.device,
        host=args.host,
        port=args.port,
    )
    await server.start_server()


if __name__ == "__main__":
    asyncio.run(main())
