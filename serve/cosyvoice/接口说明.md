# CosyVoice WebSocket 流式语音合成接口说明

## 服务信息

- **服务类型**: WebSocket 流式语音合成服务
- **默认地址**: `ws://127.0.0.1:8769`
- **协议**: WebSocket
- **音频格式**: WAV (22050Hz)

## 启动服务

```bash
# 使用默认参数启动
python serve/cosyvoice/cosyvoice_ws.py

# 自定义参数启动
python serve/cosyvoice/cosyvoice_ws.py \
    --model-dir models/CosyVoice2-0.5B \
    --device cuda \
    --host 0.0.0.0 \
    --port 8769
```

### 启动参数

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `--model-dir` | string | `models/CosyVoice2-0.5B` | CosyVoice 模型目录路径 |
| `--device` | string | `cuda` | 运行设备（cuda 或 cpu） |
| `--host` | string | `0.0.0.0` | 服务器绑定地址 |
| `--port` | int | `8769` | 服务器端口号 |

## 连接流程

### 1. 建立 WebSocket 连接

```python
import websockets
import asyncio

async def connect():
    uri = "ws://127.0.0.1:8769"
    async with websockets.connect(uri, max_size=None) as websocket:
        # 接收欢迎消息
        welcome = await websocket.recv()
        print(welcome)  # JSON 格式的欢迎消息
        
        # 后续操作...
```

### 2. 接收欢迎消息

连接成功后，服务器会发送欢迎消息（文本格式，JSON）：

```json
{
    "status": "success",
    "message": "已连接到 CosyVoice WebSocket（流式）",
    "usage": "发送 {\"type\":\"tts_stream\", \"text\":\"...\", \"mode\":\"zero_shot/cross_lingual/instruct\", ...} 开始流式合成"
}
```

## 请求接口

### 请求格式

客户端发送 JSON 文本消息，包含以下字段：

```json
{
    "type": "tts_stream",
    "mode": "zero_shot",
    "text": "待合成的文本内容",
    "prompt_audio": "asset/zero_shot_prompt.wav",
    "prompt_text": "希望你以后能够做的比我还好呀。",
    "instruct_text": "",
    "speed": 1.0,
    "seed": 0
}
```

### 请求参数说明

#### 公共参数

| 参数 | 类型 | 必填 | 默认值 | 说明 |
|------|------|------|--------|------|
| `type` | string | ✅ | - | 请求类型，固定为 `"tts_stream"` |
| `mode` | string | ✅ | - | 推理模式：`zero_shot`/`cross_lingual`/`instruct` |
| `text` | string | ✅ | - | 待合成的文本内容 |
| `prompt_audio` | string | ✅ | - | 参考音频文件路径（相对于服务器） |
| `speed` | float | ❌ | `1.0` | 语速倍数（0.5-2.0） |
| `seed` | int | ❌ | `0` | 随机种子 |

#### 模式特定参数

**零样本克隆模式 (`zero_shot`)**

| 参数 | 类型 | 必填 | 说明 |
|------|------|------|------|
| `prompt_text` | string | ✅ | 参考音频对应的文本内容 |

**跨语言克隆模式 (`cross_lingual`)**

- 无额外参数
- 仅需提供 `prompt_audio`

**指令控制模式 (`instruct`)**

| 参数 | 类型 | 必填 | 说明 |
|------|------|------|------|
| `instruct_text` | string | ✅ | 指令文本（如"用四川话说这句话"） |

### 请求示例

#### 零样本克隆

```json
{
    "type": "tts_stream",
    "mode": "zero_shot",
    "text": "八百标兵奔北坡，炮兵并排北边跑。",
    "prompt_audio": "asset/zero_shot_prompt.wav",
    "prompt_text": "希望你以后能够做的比我还好呀。",
    "speed": 1.0,
    "seed": 0
}
```

#### 跨语言克隆

```json
{
    "type": "tts_stream",
    "mode": "cross_lingual",
    "text": "Hello, welcome to use CosyVoice!",
    "prompt_audio": "asset/zero_shot_prompt.wav",
    "speed": 1.0,
    "seed": 0
}
```

#### 指令控制

```json
{
    "type": "tts_stream",
    "mode": "instruct",
    "text": "这是一段测试文本。",
    "prompt_audio": "asset/zero_shot_prompt.wav",
    "instruct_text": "用四川话说这句话",
    "speed": 1.0,
    "seed": 0
}
```

## 响应接口

### 响应流程

服务器会发送多条消息，按顺序为：

1. **开始标记**（文本消息，JSON）
2. **音频片段 1**（二进制消息）
3. **音频片段 2**（二进制消息）
4. **...**（更多音频片段）
5. **结束标记**（文本消息，JSON）

### 响应消息类型

#### 1. 开始标记

```json
{
    "type": "start",
    "message": "开始生成音频"
}
```

#### 2. 音频片段

- **格式**: 二进制数据
- **内容**: WAV 格式的音频数据
- **采样率**: 22050Hz
- **数量**: 根据文本长度自动分段

接收示例：

```python
async for msg in websocket:
    if isinstance(msg, bytes):
        # 二进制音频数据
        audio_bytes = msg
        # 可以直接保存或播放
```

#### 3. 结束标记

```json
{
    "type": "end",
    "message": "生成完成",
    "segments": 5
}
```

**字段说明**：
- `type`: 消息类型，固定为 `"end"`
- `message`: 状态消息
- `segments`: 总共发送的音频片段数量

#### 4. 错误消息

```json
{
    "status": "error",
    "message": "错误描述信息"
}
```

## 完整使用示例

### Python 客户端

```python
import asyncio
import json
import websockets
import io
import torchaudio

async def synthesize(text, mode="zero_shot"):
    uri = "ws://127.0.0.1:8769"
    
    async with websockets.connect(uri, max_size=None) as ws:
        # 1. 接收欢迎消息
        welcome = await ws.recv()
        print("连接成功:", json.loads(welcome)["message"])
        
        # 2. 发送合成请求
        request = {
            "type": "tts_stream",
            "mode": mode,
            "text": text,
            "prompt_audio": "asset/zero_shot_prompt.wav",
            "prompt_text": "希望你以后能够做的比我还好呀。",
            "speed": 1.0,
            "seed": 0
        }
        await ws.send(json.dumps(request, ensure_ascii=False))
        
        # 3. 接收流式音频
        audio_segments = []
        async for msg in ws:
            if isinstance(msg, bytes):
                # 音频片段
                buffer = io.BytesIO(msg)
                waveform, sample_rate = torchaudio.load(buffer)
                audio_segments.append(waveform.squeeze(0).numpy())
                print(f"收到音频片段 #{len(audio_segments)}")
            else:
                # 控制消息
                data = json.loads(msg)
                if data.get("type") == "start":
                    print("开始生成...")
                elif data.get("type") == "end":
                    print(f"生成完成，共 {data.get('segments')} 个片段")
                    break
                elif data.get("status") == "error":
                    print("错误:", data.get("message"))
                    break
        
        return audio_segments, sample_rate

# 运行示例
if __name__ == "__main__":
    asyncio.run(synthesize("你好，欢迎使用 CosyVoice！"))
```

### JavaScript 客户端

```javascript
const ws = new WebSocket('ws://127.0.0.1:8769');

ws.onopen = () => {
    console.log('连接成功');
};

ws.onmessage = async (event) => {
    if (event.data instanceof Blob) {
        // 二进制音频数据
        const audioBlob = event.data;
        console.log('收到音频片段');
        // 可以播放或保存
    } else {
        // 文本消息
        const data = JSON.parse(event.data);
        console.log('收到消息:', data);
        
        if (data.status === "success") {
            // 欢迎消息，发送请求
            const request = {
                type: "tts_stream",
                mode: "zero_shot",
                text: "你好，欢迎使用 CosyVoice！",
                prompt_audio: "asset/zero_shot_prompt.wav",
                prompt_text: "希望你以后能够做的比我还好呀。",
                speed: 1.0,
                seed: 0
            };
            ws.send(JSON.stringify(request));
        } else if (data.type === "end") {
            console.log('生成完成');
            ws.close();
        }
    }
};
```

## 错误处理

### 常见错误

| 错误信息 | 原因 | 解决方法 |
|---------|------|---------|
| `缺少有效的 text` | 未提供文本或文本为空 | 确保 `text` 字段非空 |
| `mode 必须是 zero_shot/cross_lingual/instruct` | 模式参数错误 | 使用正确的模式值 |
| `零样本克隆模式需要提供 prompt_text` | 缺少参考文本 | 在 `zero_shot` 模式下提供 `prompt_text` |
| `指令控制模式需要提供 instruct_text` | 缺少指令文本 | 在 `instruct` 模式下提供 `instruct_text` |
| `模型或音频加载失败` | 参考音频路径错误 | 检查 `prompt_audio` 路径是否正确 |
| `连接失败` | 服务器未启动或地址错误 | 确认服务器已启动且地址正确 |

## 性能参考

- **首包延迟**: ~600-800ms（取决于硬件和文本长度）
- **音频片段数**: 根据文本长度自动分段，平均每段 1-2 秒音频
- **总耗时**: 约为音频时长的 0.5-1 倍（实时率 RTF < 1）

## 注意事项

1. **音频路径**: `prompt_audio` 必须是服务器可访问的路径
2. **连接限制**: 建议使用持久连接处理多个请求
3. **大文本**: 长文本会自动分段生成，增加片段数量
4. **并发**: 服务器支持多客户端并发连接
5. **超时**: 建议设置合理的超时时间（推荐 60 秒）
