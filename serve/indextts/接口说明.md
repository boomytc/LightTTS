# IndexTTS WebSocket 流式语音合成接口说明

## 服务信息

- **服务类型**: WebSocket 流式语音合成服务
- **默认地址**: `ws://127.0.0.1:8770`
- **协议**: WebSocket
- **音频格式**: WAV (22050Hz)

## 启动服务

```bash
# 使用默认参数启动
python serve/indextts/indextts_ws.py

# 自定义参数启动
python serve/indextts/indextts_ws.py \
    --model-dir models/IndexTTS-2 \
    --cfg-path models/IndexTTS-2/config.yaml \
    --device cuda \
    --host 0.0.0.0 \
    --port 8770
```

### 启动参数

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `--model-dir` | string | `models/IndexTTS-2` | IndexTTS 模型目录路径 |
| `--cfg-path` | string | `models/IndexTTS-2/config.yaml` | IndexTTS 配置文件路径 |
| `--device` | string | `cuda` | 运行设备（cuda 或 cpu） |
| `--host` | string | `0.0.0.0` | 服务器绑定地址 |
| `--port` | int | `8770` | 服务器端口号 |

## 连接流程

### 1. 建立 WebSocket 连接

```python
import websockets
import asyncio

async def connect():
    uri = "ws://127.0.0.1:8770"
    async with websockets.connect(uri, max_size=None) as websocket:
        # 接收欢迎消息
        welcome = await websocket.recv()
        print(welcome)  # JSON 格式的欢迎消息
        
        # 后续操作...
```

### 2. 接收欢迎消息

连接成功后，服务器会发送欢迎消息（文本格式，JSON）：

```json
{
    "status": "success",
    "message": "已连接到 IndexTTS WebSocket（流式）",
    "usage": "发送 {\"type\":\"tts_stream\", \"text\":\"...\", \"emo_mode\":\"none/audio/vector/text\", ...} 开始流式合成"
}
```

## 请求接口

### 请求格式

客户端发送 JSON 文本消息，包含以下字段：

```json
{
    "type": "tts_stream",
    "text": "待合成的文本内容",
    "prompt_audio": "asset/zero_shot_prompt.wav",
    "emo_mode": "none",
    "interval_silence": 200,
    "max_tokens": 120,
    "use_random": false
}
```

### 请求参数说明

#### 公共参数

| 参数 | 类型 | 必填 | 默认值 | 说明 |
|------|------|------|--------|------|
| `type` | string | ✅ | - | 请求类型，固定为 `"tts_stream"` |
| `text` | string | ✅ | - | 待合成的文本内容 |
| `prompt_audio` | string | ✅ | - | 说话人参考音频文件路径 |
| `emo_mode` | string | ✅ | `"none"` | 情感控制模式：`none`/`audio`/`vector`/`text` |
| `interval_silence` | int | ❌ | `200` | 句子间静音时长（毫秒） |
| `max_tokens` | int | ❌ | `120` | 每段最大 Token 数 |
| `use_random` | bool | ❌ | `false` | 是否启用随机性 |

#### 情感控制参数

**无情感控制 (`none`)**

- 无额外参数

**情感参考音频模式 (`audio`)**

| 参数 | 类型 | 必填 | 默认值 | 说明 |
|------|------|------|--------|------|
| `emo_audio` | string | ✅ | - | 情感参考音频路径 |
| `emo_alpha` | float | ❌ | `1.0` | 情感权重（0.0-1.0） |

**情感向量模式 (`vector`)**

| 参数 | 类型 | 必填 | 默认值 | 说明 |
|------|------|------|--------|------|
| `emo_vector` | array | ✅ | - | 8 维情感向量 [高兴, 愤怒, 悲伤, 恐惧, 反感, 低落, 惊讶, 自然] |

**情感文本引导模式 (`text`)**

| 参数 | 类型 | 必填 | 默认值 | 说明 |
|------|------|------|--------|------|
| `emo_text` | string | ✅ | - | 情感引导文本 |
| `emo_alpha` | float | ❌ | `1.0` | 情感权重（0.0-1.0） |

### 请求示例

#### 无情感控制

```json
{
    "type": "tts_stream",
    "text": "大家好，我现在正在体验 AI 科技！",
    "prompt_audio": "asset/zero_shot_prompt.wav",
    "emo_mode": "none",
    "interval_silence": 200,
    "max_tokens": 120,
    "use_random": false
}
```

#### 情感参考音频

```json
{
    "type": "tts_stream",
    "text": "今天心情真好！",
    "prompt_audio": "asset/zero_shot_prompt.wav",
    "emo_mode": "audio",
    "emo_audio": "path/to/happy_voice.wav",
    "emo_alpha": 0.8,
    "interval_silence": 200,
    "max_tokens": 120,
    "use_random": false
}
```

#### 情感向量

```json
{
    "type": "tts_stream",
    "text": "这真是太棒了！",
    "prompt_audio": "asset/zero_shot_prompt.wav",
    "emo_mode": "vector",
    "emo_vector": [0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0],
    "interval_silence": 200,
    "max_tokens": 120,
    "use_random": false
}
```

**情感向量说明**：
- 数组长度必须为 8
- 顺序：[高兴, 愤怒, 悲伤, 恐惧, 反感, 低落, 惊讶, 自然]
- 每个值范围：0.0-1.0
- 建议总和不超过 1.0

#### 情感文本引导

```json
{
    "type": "tts_stream",
    "text": "今天天气真好啊！",
    "prompt_audio": "asset/zero_shot_prompt.wav",
    "emo_mode": "text",
    "emo_text": "我太开心了！",
    "emo_alpha": 0.9,
    "interval_silence": 200,
    "max_tokens": 120,
    "use_random": false
}
```

## 响应接口

### 响应流程

服务器会发送以下消息：

1. **音频数据**（二进制消息，一次性发送）
2. **结束标记**（文本消息，JSON）

### 响应消息类型

#### 1. 音频数据

- **格式**: 二进制数据
- **内容**: WAV 格式的完整音频数据
- **采样率**: 22050Hz
- **数量**: 1 次（完整音频）

接收示例：

```python
async for msg in websocket:
    if isinstance(msg, bytes):
        # 二进制音频数据（完整）
        audio_bytes = msg
        # 可以直接保存或播放
```

#### 2. 结束标记

```json
{
    "type": "end"
}
```

#### 3. 错误消息

```json
{
    "status": "error",
    "message": "错误描述信息"
}
```

## 完整使用示例

### Python 客户端

```python
import asyncio
import json
import websockets
import io
import torchaudio

async def synthesize(text, emo_mode="none"):
    uri = "ws://127.0.0.1:8770"
    
    async with websockets.connect(uri, max_size=None) as ws:
        # 1. 接收欢迎消息
        welcome = await ws.recv()
        print("连接成功:", json.loads(welcome)["message"])
        
        # 2. 发送合成请求
        request = {
            "type": "tts_stream",
            "text": text,
            "prompt_audio": "asset/zero_shot_prompt.wav",
            "emo_mode": emo_mode,
            "interval_silence": 200,
            "max_tokens": 120,
            "use_random": False
        }
        
        # 根据模式添加额外参数
        if emo_mode == "vector":
            request["emo_vector"] = [0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0]
        elif emo_mode == "text":
            request["emo_text"] = "我很开心"
            request["emo_alpha"] = 0.9
        
        await ws.send(json.dumps(request, ensure_ascii=False))
        
        # 3. 接收音频
        audio_data = None
        async for msg in ws:
            if isinstance(msg, bytes):
                # 音频数据
                audio_data = msg
                print(f"收到音频数据 ({len(msg)} 字节)")
            else:
                # 控制消息
                data = json.loads(msg)
                if data.get("type") == "end":
                    print("生成完成")
                    break
                elif data.get("status") == "error":
                    print("错误:", data.get("message"))
                    break
        
        return audio_data

# 运行示例
if __name__ == "__main__":
    asyncio.run(synthesize("大家好，我现在正在体验 AI 科技！"))
```

### JavaScript 客户端

```javascript
const ws = new WebSocket('ws://127.0.0.1:8770');

ws.onopen = () => {
    console.log('连接成功');
};

ws.onmessage = async (event) => {
    if (event.data instanceof Blob) {
        // 二进制音频数据
        const audioBlob = event.data;
        console.log('收到完整音频');
        // 可以播放或保存
    } else {
        // 文本消息
        const data = JSON.parse(event.data);
        console.log('收到消息:', data);
        
        if (data.status === "success") {
            // 欢迎消息，发送请求
            const request = {
                type: "tts_stream",
                text: "大家好，我现在正在体验 AI 科技！",
                prompt_audio: "asset/zero_shot_prompt.wav",
                emo_mode: "none",
                interval_silence: 200,
                max_tokens: 120,
                use_random: false
            };
            ws.send(JSON.stringify(request));
        } else if (data.type === "end") {
            console.log('生成完成');
            ws.close();
        }
    }
};
```

## 错误处理

### 常见错误

| 错误信息 | 原因 | 解决方法 |
|---------|------|---------|
| `缺少有效的 text` | 未提供文本或文本为空 | 确保 `text` 字段非空 |
| `emo_mode 必须是 none/audio/vector/text` | 模式参数错误 | 使用正确的情感模式值 |
| `情感参考音频模式需要提供 emo_audio` | 缺少情感音频 | 在 `audio` 模式下提供 `emo_audio` |
| `情感向量模式需要提供 emo_vector` | 缺少情感向量 | 在 `vector` 模式下提供 8 维向量 |
| `情感文本引导模式需要提供 emo_text` | 缺少引导文本 | 在 `text` 模式下提供 `emo_text` |
| `模型加载失败` | 模型路径错误或权限问题 | 检查模型路径和权限 |
| `连接失败` | 服务器未启动或地址错误 | 确认服务器已启动且地址正确 |

## 性能参考

- **生成延迟**: ~2-5 秒（取决于硬件和文本长度）
- **音频质量**: 22050Hz，高质量语音合成
- **总耗时**: 约为音频时长的 1-2 倍（实时率 RTF 1-2）

## 注意事项

1. **音频路径**: `prompt_audio` 和 `emo_audio` 必须是服务器可访问的路径
2. **情感向量**: 向量值范围 0.0-1.0，建议总和 ≤ 1.0
3. **文本分段**: 长文本会自动分段处理，`max_tokens` 控制每段长度
4. **静音间隔**: `interval_silence` 控制句子间的停顿时长
5. **并发**: 服务器支持多客户端并发连接
6. **超时**: 建议设置合理的超时时间（推荐 60 秒）
