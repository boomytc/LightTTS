#!/usr/bin/env python3
"""
CosyVoice WebSocket è¯­éŸ³åˆæˆæœåŠ¡å™¨ï¼ˆæµå¼ï¼‰
- å®¢æˆ·ç«¯å‘é€ JSONï¼š{"type":"tts_stream", "text":"...", "mode":"zero_shot/cross_lingual/instruct", ...}
- æœåŠ¡ç«¯å®æ—¶ç”ŸæˆéŸ³é¢‘å¹¶é€æ®µä»¥"äºŒè¿›åˆ¶å¸§"å‘å›å®¢æˆ·ç«¯
- åˆæˆç»“æŸåï¼Œå‘é€ JSON æ–‡æœ¬æ¶ˆæ¯ï¼š{"type":"end"}
"""

import asyncio
import json
import os
import sys
import io
import websockets
import torch
import torchaudio

project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "../.."))
matcha_path = os.path.join(project_root, "Matcha-TTS")
sys.path.insert(0, project_root)
sys.path.insert(0, matcha_path)

from cosyvoice.cli.cosyvoice import CosyVoice2
from cosyvoice.utils.file_utils import load_wav
from cosyvoice.utils.common import set_all_random_seed


class CosyVoiceWebSocketServer:
    def __init__(
        self,
        model_dir: str = "models/CosyVoice2-0.5B",
        device: str = "cuda",
        host: str = "0.0.0.0",
        port: int = 8769,
    ):
        self.model_dir = model_dir
        self.device = device
        self.host = host
        self.port = port
        self.model = None

    def load_model(self):
        """åŠ è½½æ¨¡å‹"""
        if self.model is None:
            print("æ­£åœ¨åŠ è½½ CosyVoice æ¨¡å‹...")
            is_cuda = self.device == "cuda" and torch.cuda.is_available()
            self.model = CosyVoice2(
                model_dir=self.model_dir,
                load_jit=False,
                load_trt=False,
                load_vllm=False,
                fp16=is_cuda,
                trt_concurrent=1,
                device=self.device,
            )
            print(f"âœ… CosyVoice æ¨¡å‹åŠ è½½å®Œæˆ [è®¾å¤‡: {self.device}]")
        return self.model

    def load_prompt_audio(self, prompt_audio_path: str) -> torch.Tensor:
        """åŠ è½½å‚è€ƒéŸ³é¢‘"""
        if not os.path.isfile(prompt_audio_path):
            raise FileNotFoundError(f"å‚è€ƒéŸ³é¢‘ä¸å­˜åœ¨: {prompt_audio_path}")
        return load_wav(prompt_audio_path, 16000)

    async def websocket_handler(self, websocket):
        """å¤„ç† WebSocket è¿æ¥"""
        # å‘é€æ¬¢è¿æ¶ˆæ¯
        welcome_msg = {
            "status": "success",
            "message": "å·²è¿æ¥åˆ° CosyVoice WebSocketï¼ˆæµå¼ï¼‰",
            "usage": "å‘é€ {\"type\":\"tts_stream\", \"text\":\"...\", \"mode\":\"zero_shot/cross_lingual/instruct\", ...} å¼€å§‹æµå¼åˆæˆ",
        }
        await websocket.send(json.dumps(welcome_msg, ensure_ascii=False))

        try:
            # æ”¯æŒæŒä¹…è¿æ¥ï¼Œå¯ä»¥å¤„ç†å¤šä¸ªè¯·æ±‚
            async for raw_msg in websocket:
                try:
                    data = json.loads(raw_msg)
                except Exception:
                    await websocket.send(
                        json.dumps({"status": "error", "message": "æ— æ•ˆçš„JSON"}, ensure_ascii=False)
                    )
                    continue

                if data.get("type") != "tts_stream":
                    await websocket.send(
                        json.dumps({"status": "error", "message": "ä»…æ”¯æŒ tts_stream"}, ensure_ascii=False)
                    )
                    continue

                # è§£æå‚æ•°
                text = data.get("text")
                mode = data.get("mode", "zero_shot")  # zero_shot / cross_lingual / instruct
                prompt_audio_path = data.get("prompt_audio", os.path.join(project_root, "asset", "zero_shot_prompt.wav"))
                prompt_text = data.get("prompt_text", "å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘€ã€‚")
                instruct_text = data.get("instruct_text", "")
                speed = data.get("speed", 1.0)
                seed = data.get("seed", 0)

                # å‚æ•°éªŒè¯
                if not text or not isinstance(text, str):
                    await websocket.send(
                        json.dumps({"status": "error", "message": "ç¼ºå°‘æœ‰æ•ˆçš„ text"}, ensure_ascii=False)
                    )
                    continue

                if mode not in ["zero_shot", "cross_lingual", "instruct"]:
                    await websocket.send(
                        json.dumps({"status": "error", "message": "mode å¿…é¡»æ˜¯ zero_shot/cross_lingual/instruct"}, ensure_ascii=False)
                    )
                    continue

                if mode == "zero_shot" and not prompt_text:
                    await websocket.send(
                        json.dumps({"status": "error", "message": "é›¶æ ·æœ¬å…‹éš†æ¨¡å¼éœ€è¦æä¾› prompt_text"}, ensure_ascii=False)
                    )
                    continue

                if mode == "instruct" and not instruct_text:
                    await websocket.send(
                        json.dumps({"status": "error", "message": "æŒ‡ä»¤æ§åˆ¶æ¨¡å¼éœ€è¦æä¾› instruct_text"}, ensure_ascii=False)
                    )
                    continue

                # åŠ è½½æ¨¡å‹å’Œå‚è€ƒéŸ³é¢‘
                try:
                    model = self.load_model()
                    prompt_audio = self.load_prompt_audio(prompt_audio_path)
                except Exception as e:
                    await websocket.send(
                        json.dumps({"status": "error", "message": f"æ¨¡å‹æˆ–éŸ³é¢‘åŠ è½½å¤±è´¥: {str(e)}"}, ensure_ascii=False)
                    )
                    continue

                # è®¾ç½®éšæœºç§å­
                set_all_random_seed(int(seed))

                # å‘é€å¼€å§‹æ ‡è®°
                await websocket.send(json.dumps({"type": "start", "message": "å¼€å§‹ç”ŸæˆéŸ³é¢‘"}, ensure_ascii=False))

                # æ ¹æ®æ¨¡å¼è°ƒç”¨æ¨ç†å¹¶å®æ—¶æµå¼å‘é€
                result_generator = None
                try:
                    if mode == "zero_shot":
                        result_generator = model.inference_zero_shot(
                            text,
                            prompt_text,
                            prompt_audio,
                            stream=True,  # æµå¼ç”Ÿæˆ
                            speed=float(speed),
                        )
                    elif mode == "cross_lingual":
                        result_generator = model.inference_cross_lingual(
                            text,
                            prompt_audio,
                            stream=True,
                            speed=float(speed),
                        )
                    elif mode == "instruct":
                        result_generator = model.inference_instruct2(
                            text,
                            instruct_text,
                            prompt_audio,
                            stream=True,
                            speed=float(speed),
                        )

                    # å®æ—¶æµå¼å‘é€éŸ³é¢‘ç‰‡æ®µ
                    if result_generator is not None:
                        segment_count = 0
                        for segment in result_generator:
                            audio_tensor = segment.get("tts_speech")
                            if audio_tensor is None:
                                continue

                            # å°†éŸ³é¢‘è½¬æ¢ä¸º WAV æ ¼å¼çš„å­—èŠ‚æµ
                            audio_numpy = audio_tensor.squeeze(0).cpu().numpy()
                            buffer = io.BytesIO()
                            torchaudio.save(
                                buffer,
                                torch.from_numpy(audio_numpy).unsqueeze(0),
                                model.sample_rate,
                                format="wav"
                            )
                            buffer.seek(0)
                            audio_bytes = buffer.read()

                            # ç«‹å³å‘é€äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®ï¼ˆè¾¹ç”Ÿæˆè¾¹å‘é€ï¼‰
                            await websocket.send(audio_bytes)
                            segment_count += 1

                        # åˆæˆå®Œæˆï¼Œå‘é€ç»“æŸæ ‡è®°
                        await websocket.send(json.dumps({
                            "type": "end",
                            "message": "ç”Ÿæˆå®Œæˆ",
                            "segments": segment_count
                        }, ensure_ascii=False))
                    else:
                        await websocket.send(
                            json.dumps({"status": "error", "message": "æ— æ•ˆçš„æ¨¡å¼"}, ensure_ascii=False)
                        )
                except Exception as e:
                    await websocket.send(
                        json.dumps({"status": "error", "message": f"æ¨ç†å¤±è´¥: {str(e)}"}, ensure_ascii=False)
                    )
                    continue

        except websockets.exceptions.ConnectionClosed:
            # å®¢æˆ·ç«¯ä¸­æ–­è¿æ¥
            return
        except Exception as e:
            # å‘ç”Ÿé”™è¯¯æ—¶è¿”å›é”™è¯¯æ¶ˆæ¯
            try:
                await websocket.send(
                    json.dumps({"status": "error", "message": f"æœåŠ¡å™¨é”™è¯¯: {str(e)}"}, ensure_ascii=False)
                )
            except Exception:
                pass

    async def start_server(self):
        """å¯åŠ¨ WebSocket æœåŠ¡å™¨"""
        print(f"å¯åŠ¨ CosyVoice æµå¼ WebSocket æœåŠ¡å™¨: ws://{self.host}:{self.port}")
        
        # é¢„åŠ è½½æ¨¡å‹
        self.load_model()
        
        print(f"\nğŸš€ æœåŠ¡å™¨å·²å°±ç»ªï¼Œç­‰å¾…å®¢æˆ·ç«¯è¿æ¥...")
        async with websockets.serve(self.websocket_handler, self.host, self.port, max_size=None):
            await asyncio.Future()  # è¿è¡Œç›´åˆ°æ‰‹åŠ¨åœæ­¢


async def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description="CosyVoice WebSocket æµå¼è¯­éŸ³åˆæˆæœåŠ¡",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument(
        "--model-dir",
        type=str,
        default="models/CosyVoice2-0.5B",
        help="CosyVoice æ¨¡å‹ç›®å½•è·¯å¾„"
    )
    parser.add_argument(
        "--device",
        type=str,
        default="cuda" if torch.cuda.is_available() else "cpu",
        choices=["cuda", "cpu"],
        help="è¿è¡Œè®¾å¤‡ï¼ˆcuda æˆ– cpuï¼‰"
    )
    parser.add_argument(
        "--host",
        type=str,
        default="0.0.0.0",
        help="æœåŠ¡å™¨ç»‘å®šåœ°å€"
    )
    parser.add_argument(
        "--port",
        type=int,
        default=8769,
        help="æœåŠ¡å™¨ç«¯å£å·"
    )
    
    args = parser.parse_args()
    
    server = CosyVoiceWebSocketServer(
        model_dir=args.model_dir,
        device=args.device,
        host=args.host,
        port=args.port,
    )
    await server.start_server()


if __name__ == "__main__":
    asyncio.run(main())
