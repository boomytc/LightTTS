# CosyVoice WebSocket 流式语音合成接口说明

## 服务信息

- **服务类型**: WebSocket 流式语音合成服务
- **默认地址**: `ws://127.0.0.1:8769`
- **协议**: WebSocket
- **音频格式**: WAV (22050Hz)

## 启动服务

```bash
# 使用默认参数启动
python serve/cosyvoice/cosyvoice_ws.py

# 自定义参数启动
python serve/cosyvoice/cosyvoice_ws.py \
    --model-dir models/CosyVoice2-0.5B \
    --device cuda \
    --host 0.0.0.0 \
    --port 8769
```

### 启动参数

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `--model-dir` | string | `models/CosyVoice2-0.5B` | CosyVoice 模型目录路径 |
| `--device` | string | `cuda` | 运行设备（cuda 或 cpu） |
| `--host` | string | `0.0.0.0` | 服务器绑定地址 |
| `--port` | int | `8769` | 服务器端口号 |

## 连接流程

### 1. 建立 WebSocket 连接

```python
import websockets
import asyncio

async def connect():
    uri = "ws://127.0.0.1:8769"
    async with websockets.connect(uri, max_size=None) as websocket:
        # 接收欢迎消息
        welcome = await websocket.recv()
        print(welcome)  # JSON 格式的欢迎消息
        
        # 后续操作...
```

### 2. 接收欢迎消息

连接成功后，服务器会发送欢迎消息（文本格式，JSON）：

```json
{
    "status": "success",
    "session_id": "550e8400-e29b-41d4-a716-446655440000",
    "message": "已连接到 CosyVoice WebSocket（流式）",
    "usage": "发送 {\"type\":\"tts_stream\", \"text\":\"...\", \"mode\":\"zero_shot/cross_lingual/instruct\", ...} 开始流式合成"
}
```

**字段说明**：
- `status`: 连接状态，成功为 `"success"`
- `session_id`: 会话ID（UUID格式），由服务端自动生成，用于追踪连接
- `message`: 欢迎消息
- `usage`: 使用说明

## 请求接口

### 请求格式

客户端发送 JSON 文本消息，包含以下字段：

```json
{
    "type": "tts_stream",
    "mode": "zero_shot",
    "text": "待合成的文本内容",
    "prompt_audio": "asset/zero_shot_prompt.wav",
    "prompt_text": "希望你以后能够做的比我还好呀。",
    "instruct_text": "",
    "speed": 1.0,
    "seed": 0
}
```

### 请求参数说明

#### 公共参数

| 参数 | 类型 | 必填 | 默认值 | 说明 |
|------|------|------|--------|------|
| `type` | string | 是 | - | 请求类型，固定为 `"tts_stream"` |
| `mode` | string | 是 | - | 推理模式：`zero_shot`/`cross_lingual`/`instruct` |
| `text` | string | 是 | - | 待合成的文本内容 |
| `prompt_audio` | string | 是 | - | 参考音频文件路径（相对于服务器） |
| `speed` | float | 否 | `1.0` | 语速倍数（0.5-2.0） |
| `seed` | int | 否 | `0` | 随机种子 |

#### 模式特定参数

**零样本克隆模式 (`zero_shot`)**

| 参数 | 类型 | 必填 | 说明 |
|------|------|------|------|
| `prompt_text` | string | 是 | 参考音频对应的文本内容 |

**跨语言克隆模式 (`cross_lingual`)**

- 无额外参数
- 仅需提供 `prompt_audio`

**指令控制模式 (`instruct`)**

| 参数 | 类型 | 必填 | 说明 |
|------|------|------|------|
| `instruct_text` | string | 是 | 指令文本（如"用四川话说这句话"） |

### 请求示例

#### 零样本克隆

```json
{
    "type": "tts_stream",
    "mode": "zero_shot",
    "text": "八百标兵奔北坡，炮兵并排北边跑。",
    "prompt_audio": "asset/zero_shot_prompt.wav",
    "prompt_text": "希望你以后能够做的比我还好呀。",
    "speed": 1.0,
    "seed": 0
}
```

#### 跨语言克隆

```json
{
    "type": "tts_stream",
    "mode": "cross_lingual",
    "text": "Hello, welcome to use CosyVoice!",
    "prompt_audio": "asset/zero_shot_prompt.wav",
    "speed": 1.0,
    "seed": 0
}
```

#### 指令控制

```json
{
    "type": "tts_stream",
    "mode": "instruct",
    "text": "这是一段测试文本。",
    "prompt_audio": "asset/zero_shot_prompt.wav",
    "instruct_text": "用四川话说这句话",
    "speed": 1.0,
    "seed": 0
}
```

## 响应接口

### 响应流程

服务器会发送多条消息，按顺序为：

1. **开始标记**（文本消息，JSON）
2. **音频片段 1**（二进制消息）
3. **音频片段 2**（二进制消息）
4. **...**（更多音频片段）
5. **结束标记**（文本消息，JSON）

### 响应消息类型

#### 1. 开始标记

```json
{
    "type": "start",
    "task_id": "7c9e6679-7425-40de-944b-e07fc1f90ae7",
    "session_id": "550e8400-e29b-41d4-a716-446655440000",
    "message": "开始生成音频"
}
```

**字段说明**：
- `type`: 消息类型，固定为 `"start"`
- `task_id`: 任务ID（UUID格式），由服务端自动生成，用于追踪单个TTS请求
- `session_id`: 会话ID，与连接时的会话ID相同
- `message`: 状态消息

#### 2. 音频片段

- **格式**: 二进制数据
- **内容**: WAV 格式的音频数据
- **采样率**: 22050Hz
- **数量**: 根据文本长度自动分段

接收示例：

```python
async for msg in websocket:
    if isinstance(msg, bytes):
        # 二进制音频数据
        audio_bytes = msg
        # 可以直接保存或播放
```

#### 3. 结束标记

```json
{
    "type": "end",
    "task_id": "7c9e6679-7425-40de-944b-e07fc1f90ae7",
    "session_id": "550e8400-e29b-41d4-a716-446655440000",
    "message": "生成完成",
    "segments": 5
}
```

**字段说明**：
- `type`: 消息类型，固定为 `"end"`
- `task_id`: 任务ID，与开始标记中的任务ID相同
- `session_id`: 会话ID
- `message`: 状态消息
- `segments`: 总共发送的音频片段数量

#### 4. 错误消息

```json
{
    "status": "error",
    "task_id": "7c9e6679-7425-40de-944b-e07fc1f90ae7",
    "session_id": "550e8400-e29b-41d4-a716-446655440000",
    "message": "错误描述信息"
}
```

**字段说明**：
- `status`: 错误状态，固定为 `"error"`
- `task_id`: 任务ID（如果任务已创建）
- `session_id`: 会话ID
- `message`: 错误描述信息

#### 5. 任务状态查询

客户端可以发送任务状态查询请求：

```json
{
    "type": "task_status",
    "task_id": "7c9e6679-7425-40de-944b-e07fc1f90ae7"
}
```

服务器响应：

```json
{
    "type": "task_status",
    "session_id": "550e8400-e29b-41d4-a716-446655440000",
    "task_id": "7c9e6679-7425-40de-944b-e07fc1f90ae7",
    "status": "completed",
    "created_at": "2024-11-04T10:30:00.123456",
    "completed_at": "2024-11-04T10:30:05.678901",
    "error_message": null
}
```

**状态值**：
- `pending`: 任务已创建，等待加入队列
- `running`: 任务正在执行（已从队列中取出）
- `completed`: 任务已完成
- `failed`: 任务失败
- `cancelled`: 任务已取消

**注意**: 由于使用了全局推理队列，任务在 `pending` 状态时实际上是在排队等待。当轮到该任务时，状态会变为 `running`。

## 完整使用示例

### Python 客户端

```python
import asyncio
import json
import websockets
import io
import torchaudio

async def synthesize(text, mode="zero_shot"):
    uri = "ws://127.0.0.1:8769"
    
    async with websockets.connect(uri, max_size=None) as ws:
        # 1. 接收欢迎消息
        welcome = await ws.recv()
        print("连接成功:", json.loads(welcome)["message"])
        
        # 2. 发送合成请求
        request = {
            "type": "tts_stream",
            "mode": mode,
            "text": text,
            "prompt_audio": "asset/zero_shot_prompt.wav",
            "prompt_text": "希望你以后能够做的比我还好呀。",
            "speed": 1.0,
            "seed": 0
        }
        await ws.send(json.dumps(request, ensure_ascii=False))
        
        # 3. 接收流式音频
        audio_segments = []
        async for msg in ws:
            if isinstance(msg, bytes):
                # 音频片段
                buffer = io.BytesIO(msg)
                waveform, sample_rate = torchaudio.load(buffer)
                audio_segments.append(waveform.squeeze(0).numpy())
                print(f"收到音频片段 #{len(audio_segments)}")
            else:
                # 控制消息
                data = json.loads(msg)
                if data.get("type") == "start":
                    print("开始生成...")
                elif data.get("type") == "end":
                    print(f"生成完成，共 {data.get('segments')} 个片段")
                    break
                elif data.get("status") == "error":
                    print("错误:", data.get("message"))
                    break
        
        return audio_segments, sample_rate

# 运行示例
if __name__ == "__main__":
    asyncio.run(synthesize("你好，欢迎使用 CosyVoice！"))
```

### JavaScript 客户端

```javascript
const ws = new WebSocket('ws://127.0.0.1:8769');

ws.onopen = () => {
    console.log('连接成功');
};

ws.onmessage = async (event) => {
    if (event.data instanceof Blob) {
        // 二进制音频数据
        const audioBlob = event.data;
        console.log('收到音频片段');
        // 可以播放或保存
    } else {
        // 文本消息
        const data = JSON.parse(event.data);
        console.log('收到消息:', data);
        
        if (data.status === "success") {
            // 欢迎消息，发送请求
            const request = {
                type: "tts_stream",
                mode: "zero_shot",
                text: "你好，欢迎使用 CosyVoice！",
                prompt_audio: "asset/zero_shot_prompt.wav",
                prompt_text: "希望你以后能够做的比我还好呀。",
                speed: 1.0,
                seed: 0
            };
            ws.send(JSON.stringify(request));
        } else if (data.type === "end") {
            console.log('生成完成');
            ws.close();
        }
    }
};
```

## 错误处理

### 常见错误

| 错误信息 | 原因 | 解决方法 |
|---------|------|---------|
| `缺少有效的 text` | 未提供文本或文本为空 | 确保 `text` 字段非空 |
| `mode 必须是 zero_shot/cross_lingual/instruct` | 模式参数错误 | 使用正确的模式值 |
| `零样本克隆模式需要提供 prompt_text` | 缺少参考文本 | 在 `zero_shot` 模式下提供 `prompt_text` |
| `指令控制模式需要提供 instruct_text` | 缺少指令文本 | 在 `instruct` 模式下提供 `instruct_text` |
| `模型或音频加载失败` | 参考音频路径错误 | 检查 `prompt_audio` 路径是否正确 |
| `连接失败` | 服务器未启动或地址错误 | 确认服务器已启动且地址正确 |

## 性能参考

- **首包延迟**: ~600-800ms（取决于硬件和文本长度）
- **音频片段数**: 根据文本长度自动分段，平均每段 1-2 秒音频
- **总耗时**: 约为音频时长的 0.5-1 倍（实时率 RTF < 1）

## 会话和任务管理

### 会话（Session）

- **自动创建**: WebSocket 连接建立时自动创建
- **会话ID**: 由服务端生成的 UUID，在欢迎消息中返回
- **生命周期**: 连接建立到断开
- **用途**: 追踪连接，管理该连接下的所有任务

### 任务（Task）

- **自动创建**: 每个 TTS 请求自动创建一个任务
- **任务ID**: 由服务端自动生成的 UUID，在开始标记中返回
- **状态追踪**: `pending → queued → running → completed/failed`
- **用途**: 追踪单个 TTS 请求的执行状态
- **清理**: 任务完成后保留 5 分钟，之后自动清理

### 推理队列

服务器使用**全局推理队列**管理并发：

- **单模型实例**: 服务器只加载一个模型实例
- **多客户端连接**: 支持多个客户端同时连接
- **顺序处理**: 所有请求按接收顺序排队，同时只处理 1 个请求
- **自动排队**: 当有请求正在处理时，新请求会收到 `queued` 消息

#### 请求处理流程

```
客户端A: 请求1 → 立即处理 → 完成
客户端B: 请求2 → 排队等待 → 请求1完成后处理 → 完成
客户端C: 请求3 → 排队等待 → 请求2完成后处理 → 完成
```

#### 消息顺序

```json
// 1. 任务创建后立即收到排队消息
{"type": "queued", "task_id": "xxx", "message": "任务已加入队列，等待处理"}

// 2. 轮到该任务时收到开始消息
{"type": "start", "task_id": "xxx", "message": "开始生成音频"}

// 3. 接收音频片段（二进制数据）
// ...

// 4. 完成消息
{"type": "end", "task_id": "xxx", "message": "生成完成"}
```

### 使用建议

1. **保存任务ID**: 从 `queued` 或 `start` 消息中获取 `task_id`，用于后续追踪
2. **状态查询**: 可以使用 `task_status` 消息查询任务状态
3. **持久连接**: 单个连接可以发送多个请求，每个请求会获得不同的 `task_id`
4. **日志追踪**: 使用 `session_id` 和 `task_id` 进行日志关联
5. **排队等待**: 如果收到 `queued` 消息，说明前面有其他请求正在处理，需要等待

## 注意事项

1. **音频路径**: `prompt_audio` 必须是服务器可访问的路径
2. **连接限制**: 建议使用持久连接处理多个请求
3. **大文本**: 长文本会自动分段生成，增加片段数量
4. **并发**: 服务器支持多客户端并发连接
5. **超时**: 建议设置合理的超时时间（推荐 60 秒）
6. **任务ID**: 由服务端自动生成，客户端无需提供
7. **会话ID**: 用于追踪连接，所有响应消息都包含会话ID
