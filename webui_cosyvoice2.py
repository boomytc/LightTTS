import os
import sys
import argparse
import gradio as gr
import numpy as np
import torch
import torchaudio
import random
import librosa
ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.append('{}/third_party/Matcha-TTS'.format(ROOT_DIR))
from cosyvoice.cli.cosyvoice import CosyVoice2
from cosyvoice.utils.file_utils import load_wav
from cosyvoice.utils.common import set_all_random_seed

inference_mode_list = ['é›¶æ ·æœ¬è¯­éŸ³å…‹éš†', 'è·¨è¯­è¨€è¯­éŸ³åˆæˆ', 'ç²¾ç»†æŽ§åˆ¶åˆæˆ', 'æŒ‡ä»¤æŽ§åˆ¶åˆæˆ']
stream_mode_list = [('å¦', False), ('æ˜¯', True)]
max_val = 0.8

def generate_seed():
    seed = random.randint(1, 100000000)
    return {
        "__type__": "update",
        "value": seed
    }

def postprocess(speech, top_db=60, hop_length=220, win_length=440):
    speech, _ = librosa.effects.trim(
        speech, top_db=top_db,
        frame_length=win_length,
        hop_length=hop_length
    )
    if speech.abs().max() > max_val:
        speech = speech / speech.abs().max() * max_val
    speech = torch.concat([speech, torch.zeros(1, int(cosyvoice.sample_rate * 0.2))], dim=1)
    return speech

def generate_audio(tts_text, mode_checkbox_group, prompt_text, prompt_wav_upload, prompt_wav_record, instruct_text,
                   seed, stream, speed):
    prompt_wav = prompt_wav_upload or prompt_wav_record
    
    if prompt_wav is None:
        yield (cosyvoice.sample_rate, default_data)
        return
    
    if torchaudio.info(prompt_wav).sample_rate < prompt_sr:
        yield (cosyvoice.sample_rate, default_data)
        return
    
    prompt_speech_16k = postprocess(load_wav(prompt_wav, prompt_sr))
    set_all_random_seed(seed)
    
    if mode_checkbox_group == 'é›¶æ ·æœ¬è¯­éŸ³å…‹éš†':
        if not prompt_text:
            yield (cosyvoice.sample_rate, default_data)
            return
        for i in cosyvoice.inference_zero_shot(tts_text, prompt_text, prompt_speech_16k, stream=stream, speed=speed):
            yield (cosyvoice.sample_rate, i['tts_speech'].numpy().flatten())
    
    elif mode_checkbox_group == 'è·¨è¯­è¨€è¯­éŸ³åˆæˆ':
        for i in cosyvoice.inference_cross_lingual(tts_text, prompt_speech_16k, stream=stream, speed=speed):
            yield (cosyvoice.sample_rate, i['tts_speech'].numpy().flatten())
    
    elif mode_checkbox_group == 'ç²¾ç»†æŽ§åˆ¶åˆæˆ':
        for i in cosyvoice.inference_cross_lingual(tts_text, prompt_speech_16k, stream=stream, speed=speed):
            yield (cosyvoice.sample_rate, i['tts_speech'].numpy().flatten())
    
    elif mode_checkbox_group == 'æŒ‡ä»¤æŽ§åˆ¶åˆæˆ':
        if not instruct_text:
            yield (cosyvoice.sample_rate, default_data)
            return
        for i in cosyvoice.inference_instruct2(tts_text, instruct_text, prompt_speech_16k, stream=stream, speed=speed):
            yield (cosyvoice.sample_rate, i['tts_speech'].numpy().flatten())

def main():
    with gr.Blocks() as demo:
        gr.Markdown("### CosyVoice2 è¯­éŸ³åˆæˆç³»ç»Ÿ")
        
        tts_text = gr.Textbox(label="åˆæˆæ–‡æœ¬", lines=2, value="æ”¶åˆ°å¥½å‹ä»Žè¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸Žæ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚")
        
        with gr.Row():
            mode_checkbox_group = gr.Radio(choices=inference_mode_list, label='æŽ¨ç†æ¨¡å¼', value=inference_mode_list[0])
            stream = gr.Radio(choices=stream_mode_list, label='æµå¼æŽ¨ç†', value=stream_mode_list[0][1])
            speed = gr.Number(value=1, label="é€Ÿåº¦", minimum=0.5, maximum=2.0, step=0.1)
            with gr.Column():
                seed_button = gr.Button(value="ðŸŽ²")
                seed = gr.Number(value=0, label="ç§å­")

        with gr.Row():
            prompt_wav_upload = gr.Audio(sources='upload', type='filepath', label='éŸ³é¢‘æ–‡ä»¶')
            prompt_wav_record = gr.Audio(sources='microphone', type='filepath', label='å½•åˆ¶éŸ³é¢‘')
        
        prompt_text = gr.Textbox(label="promptæ–‡æœ¬", value='å¸Œæœ›ä½ ä»¥åŽèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚')
        instruct_text = gr.Textbox(label="æŒ‡ä»¤æ–‡æœ¬", value='ç”¨å››å·è¯è¯´è¿™å¥è¯')
        
        generate_button = gr.Button("ç”ŸæˆéŸ³é¢‘")
        audio_output = gr.Audio(label="åˆæˆéŸ³é¢‘", autoplay=True, streaming=True)

        seed_button.click(generate_seed, inputs=[], outputs=seed)
        generate_button.click(generate_audio,
                              inputs=[tts_text, mode_checkbox_group, prompt_text, prompt_wav_upload, prompt_wav_record, instruct_text,
                                      seed, stream, speed],
                              outputs=[audio_output])
    
    demo.queue(max_size=4, default_concurrency_limit=2)
    demo.launch(inbrowser=True, server_name='127.0.0.1', server_port=args.port, share=True)

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--port',
                        type=int,
                        default=8001)
    parser.add_argument('--model_dir',
                        type=str,
                        default='pretrained_models/CosyVoice2-0.5B',
                        help='local path or modelscope repo id')
    args = parser.parse_args()
    
    cosyvoice = CosyVoice2(args.model_dir)

    prompt_sr = 16000
    default_data = np.zeros(cosyvoice.sample_rate)
    main()