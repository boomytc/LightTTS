import os
import sys
import numpy as np
import torch
import gradio as gr  
from typing import Optional, Tuple
from pathlib import Path

current_dir = os.path.dirname(__file__)
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.append(project_root)
os.environ["TOKENIZERS_PARALLELISM"] = "false"

from voxcpm.core import VoxCPM


class VoxCPMDemo:
    def __init__(self) -> None:
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸš€ Running on device: {self.device}")

        # TTS æ¨¡å‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        self.voxcpm_model: Optional[VoxCPM] = None
        self.tts_model_path = "models/VoxCPM-0.5B"

    # ---------- æ¨¡å‹è¾…åŠ©æ–¹æ³• ----------

    def get_or_load_voxcpm(self) -> VoxCPM:
        if self.voxcpm_model is not None:
            return self.voxcpm_model
        print("æ¨¡å‹æœªåŠ è½½ï¼Œæ­£åœ¨åˆå§‹åŒ–...")
        print(f"ä½¿ç”¨æ¨¡å‹è·¯å¾„: {self.tts_model_path}")
        self.voxcpm_model = VoxCPM.from_pretrained(
            self.tts_model_path,
            local_files_only=True,
            device=self.device,
        )
        print("æ¨¡å‹åŠ è½½æˆåŠŸã€‚")
        return self.voxcpm_model

    # ---------- åŠŸèƒ½æ¥å£ ----------
    def prompt_wav_recognition(self, prompt_wav: Optional[str]) -> str:
        # ç§»é™¤è‡ªåŠ¨è¯†åˆ«åŠŸèƒ½ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        return ""

    def generate_tts_audio(
        self,
        text_input: str,
        prompt_wav_path_input: Optional[str] = None,
        prompt_text_input: Optional[str] = None,
        cfg_value_input: float = 2.0,
        inference_timesteps_input: int = 10,
        do_normalize: bool = True,
        denoise: bool = True,
    ) -> Tuple[int, np.ndarray]:
        """
        ä½¿ç”¨ VoxCPM ä»æ–‡æœ¬ç”Ÿæˆè¯­éŸ³ï¼›å¯é€‰å‚è€ƒéŸ³é¢‘ç”¨äºè¯­éŸ³é£æ ¼æŒ‡å¯¼ã€‚
        è¿”å› (é‡‡æ ·ç‡, æ³¢å½¢æ•°ç»„)
        """
        current_model = self.get_or_load_voxcpm()

        text = (text_input or "").strip()
        if len(text) == 0:
            raise ValueError("è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬ã€‚")

        prompt_wav_path = prompt_wav_path_input if prompt_wav_path_input else None
        prompt_text = prompt_text_input if prompt_text_input else None

        print(f"æ­£åœ¨ä¸ºæ–‡æœ¬ç”ŸæˆéŸ³é¢‘: '{text[:60]}...'")
        wav = current_model.generate(
            text=text,
            prompt_text=prompt_text,
            prompt_wav_path=prompt_wav_path,
            cfg_value=float(cfg_value_input),
            inference_timesteps=int(inference_timesteps_input),
            normalize=do_normalize,
            denoise=denoise,
        )
        return (16000, wav)


# ---------- UI æ„å»ºå™¨ ----------

def create_demo_interface(demo: VoxCPMDemo):
    """æ„å»º VoxCPM æ¼”ç¤ºçš„ Gradio UI ç•Œé¢ã€‚"""
    # é™æ€èµ„æºï¼ˆlogo è·¯å¾„ï¼‰
    gr.set_static_paths(paths=[Path.cwd().absolute()/"assets"])

    with gr.Blocks(
        theme=gr.themes.Soft(
            primary_hue="blue",
            secondary_hue="gray",
            neutral_hue="slate",
            font=[gr.themes.GoogleFont("Inter"), "Arial", "sans-serif"]
        ),
        css="""
        .logo-container {
            text-align: center;
            margin: 0.5rem 0 1rem 0;
        }
        .logo-container img {
            height: 80px;
            width: auto;
            max-width: 200px;
            display: inline-block;
        }
        /* Bold accordion labels */
        #acc_quick details > summary,
        #acc_tips details > summary {
            font-weight: 600 !important;
            font-size: 1.1em !important;
        }
        /* Bold labels for specific checkboxes */
        #chk_denoise label,
        #chk_denoise span,
        #chk_normalize label,
        #chk_normalize span {
            font-weight: 600;
        }
        """
    ) as interface:
        # é¡µå¤´ logo
        gr.HTML('<div class="logo-container"><img src="/gradio_api/file=assets/voxcpm_logo.png" alt="VoxCPM Logo"></div>')

        # å¿«é€Ÿå…¥é—¨
        with gr.Accordion("ğŸ“‹ å¿«é€Ÿå…¥é—¨", open=False, elem_id="acc_quick"):
            gr.Markdown("""
            ### ä½¿ç”¨è¯´æ˜
            1. **ï¼ˆå¯é€‰ï¼‰æä¾›å‚è€ƒå£°éŸ³** - ä¸Šä¼ æˆ–å½•åˆ¶ä¸€æ®µéŸ³é¢‘ï¼Œä¸ºå£°éŸ³åˆæˆæä¾›éŸ³è‰²ã€è¯­è°ƒå’Œæƒ…æ„Ÿç­‰ä¸ªæ€§åŒ–ç‰¹å¾
            2. **ï¼ˆå¯é€‰ï¼‰è¾“å…¥å‚è€ƒæ–‡æœ¬** - å¦‚æœæä¾›äº†å‚è€ƒè¯­éŸ³ï¼Œè¯·è¾“å…¥å…¶å¯¹åº”çš„æ–‡æœ¬å†…å®¹
            3. **è¾“å…¥ç›®æ ‡æ–‡æœ¬** - è¾“å…¥æ‚¨å¸Œæœ›æ¨¡å‹æœ—è¯»çš„æ–‡å­—å†…å®¹
            4. **ç”Ÿæˆè¯­éŸ³** - ç‚¹å‡»"ç”Ÿæˆ"æŒ‰é’®ï¼Œå³å¯åˆ›é€ å‡ºéŸ³é¢‘
            """)

        # ä½¿ç”¨å»ºè®®
        with gr.Accordion("ğŸ’¡ ä½¿ç”¨å»ºè®®", open=False, elem_id="acc_tips"):
            gr.Markdown("""
            ### å‚è€ƒè¯­éŸ³é™å™ª
            - **å¯ç”¨**ï¼šé€šè¿‡ ZipEnhancer ç»„ä»¶æ¶ˆé™¤èƒŒæ™¯å™ªéŸ³ï¼Œè·å¾—æ›´å¥½çš„éŸ³è´¨
            - **ç¦ç”¨**ï¼šä¿ç•™åŸå§‹éŸ³é¢‘çš„èƒŒæ™¯ç¯å¢ƒå£°ï¼Œå¦‚æœæƒ³å¤åˆ»ç›¸åº”å£°å­¦ç¯å¢ƒ

            ### æ–‡æœ¬æ­£åˆ™åŒ–
            - **å¯ç”¨**ï¼šä½¿ç”¨ WeTextProcessing ç»„ä»¶ï¼Œå¯å¤„ç†å¸¸è§æ–‡æœ¬
            - **ç¦ç”¨**ï¼šå°†ä½¿ç”¨ VoxCPM å†…ç½®çš„æ–‡æœ¬ç†è§£èƒ½åŠ›ã€‚æ”¯æŒéŸ³ç´ è¾“å…¥ï¼ˆå¦‚ {da4}{jia1}å¥½ï¼‰å’Œå…¬å¼ç¬¦å·åˆæˆ

            ### CFG å€¼
            - **è°ƒä½**ï¼šå¦‚æœæç¤ºè¯­éŸ³å¬èµ·æ¥ä¸è‡ªç„¶æˆ–è¿‡äºå¤¸å¼ 
            - **è°ƒé«˜**ï¼šä¸ºæ›´å¥½åœ°è´´åˆæç¤ºéŸ³é¢‘çš„é£æ ¼æˆ–è¾“å…¥æ–‡æœ¬

            ### æ¨ç†æ—¶é—´æ­¥
            - **è°ƒä½**ï¼šåˆæˆé€Ÿåº¦æ›´å¿«
            - **è°ƒé«˜**ï¼šåˆæˆè´¨é‡æ›´ä½³
            """)

        # Main controls
        with gr.Row():
            with gr.Column():
                prompt_wav = gr.Audio(
                    sources=["upload", 'microphone'],
                    type="filepath",
                    label="å‚è€ƒè¯­éŸ³ï¼ˆå¯é€‰ï¼Œæˆ–è®© VoxCPM è‡ªç”±å‘æŒ¥ï¼‰",
                    value="./examples/example.wav",
                )
                DoDenoisePromptAudio = gr.Checkbox(
                    value=False,
                    label="å‚è€ƒè¯­éŸ³å¢å¼º",
                    elem_id="chk_denoise",
                    info="æˆ‘ä»¬ä½¿ç”¨ ZipEnhancer æ¨¡å‹å¯¹å‚è€ƒéŸ³é¢‘è¿›è¡Œé™å™ªã€‚"
                )
                with gr.Row():
                    prompt_text = gr.Textbox(
                        value="æ¯å¤©åªéœ€å¬å‡ åˆ†é’Ÿï¼Œä½ å°±èƒ½é€šè¿‡è°ƒèŠ‚å¿ƒæ€æ¥æ¶ˆé™¤è´Ÿé¢æƒ³æ³•ï¼Œè®©æ€ç»´å˜å¾—æ›´ç§¯æã€‚",
                        label="å‚è€ƒæ–‡æœ¬",
                        placeholder="è¯·è¾“å…¥å‚è€ƒæ–‡æœ¬ã€‚æ”¯æŒè‡ªåŠ¨è¯†åˆ«ï¼Œæ‚¨å¯ä»¥è‡ªè¡Œä¿®æ­£ç»“æœ..."
                    )
                run_btn = gr.Button("ç”Ÿæˆè¯­éŸ³", variant="primary")
                gr.Markdown("**æ³¨æ„**ï¼šè‡ªåŠ¨è¯­éŸ³è¯†åˆ«å·²è¢«ç¦ç”¨ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥ä¸éŸ³é¢‘å¯¹åº”çš„å‚è€ƒæ–‡æœ¬")

            with gr.Column():
                cfg_value = gr.Slider(
                    minimum=1.0,
                    maximum=3.0,
                    value=2.0,
                    step=0.1,
                    label="CFG å€¼ï¼ˆå¼•å¯¼å°ºåº¦ï¼‰",
                    info="è¾ƒé«˜çš„å€¼å¢åŠ å¯¹æç¤ºçš„éµå¾ªï¼Œè¾ƒä½çš„å€¼å…è®¸æ›´å¤šåˆ›é€ æ€§"
                )
                inference_timesteps = gr.Slider(
                    minimum=4,
                    maximum=30,
                    value=10,
                    step=1,
                    label="æ¨ç†æ—¶é—´æ­¥",
                    info="ç”Ÿæˆçš„æ¨ç†æ—¶é—´æ­¥æ•°ï¼ˆè¾ƒé«˜çš„å€¼å¯èƒ½æé«˜è´¨é‡ä½†é€Ÿåº¦è¾ƒæ…¢ï¼‰"
                )
                with gr.Row():
                    text = gr.Textbox(
                        value="VoxCPM æ˜¯æ¥è‡ª ModelBest çš„åˆ›æ–°ç«¯åˆ°ç«¯ TTS æ¨¡å‹ï¼Œæ—¨åœ¨ç”Ÿæˆé«˜åº¦é€¼çœŸçš„è¯­éŸ³ã€‚",
                        label="ç›®æ ‡æ–‡æœ¬",
                    )
                with gr.Row():
                    DoNormalizeText = gr.Checkbox(
                        value=False,
                        label="æ–‡æœ¬æ ‡å‡†åŒ–",
                        elem_id="chk_normalize",
                        info="æˆ‘ä»¬ä½¿ç”¨ wetext åº“å¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œæ ‡å‡†åŒ–ã€‚"
                    )
                audio_output = gr.Audio(label="è¾“å‡ºéŸ³é¢‘")

        # ç»„ä»¶è¿æ¥
        run_btn.click(
            fn=demo.generate_tts_audio,
            inputs=[text, prompt_wav, prompt_text, cfg_value, inference_timesteps, DoNormalizeText, DoDenoisePromptAudio],
            outputs=[audio_output],
            show_progress=True,
            api_name="generate",
        )

    return interface


def run_demo(server_name: str = "localhost", server_port: int = 7860, show_error: bool = True):
    demo = VoxCPMDemo()
    interface = create_demo_interface(demo)
    interface.queue(max_size=10).launch(server_name=server_name, server_port=server_port, show_error=show_error)


if __name__ == "__main__":
    run_demo()