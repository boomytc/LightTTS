import os
import sys

current_dir = os.path.dirname(__file__)
project_root = os.path.dirname(os.path.dirname(current_dir))
if project_root not in sys.path:
    sys.path.append(project_root)

import tempfile
from typing import Optional, Tuple

import gradio as gr
import numpy as np
import soundfile as sf
import torch

from voxcpm.core import VoxCPM
from voxcpm.model.voxcpm import VoxCPMModel

os.environ["TOKENIZERS_PARALLELISM"] = "false"

if torch.cuda.is_available():
    torch.set_float32_matmul_precision("high")

try:
    import torch._dynamo as dynamo
    dynamo.config.suppress_errors = True  # type: ignore
except Exception:
    pass


def _disable_optimize(self: VoxCPMModel):
    """Disable torch.compile optimizations that fail under some CUDA setups."""
    self.base_lm.forward_step = self.base_lm.forward_step
    self.residual_lm.forward_step = self.residual_lm.forward_step
    self.feat_encoder_step = self.feat_encoder
    self.feat_decoder.estimator = self.feat_decoder.estimator
    return self


VoxCPMModel.optimize = _disable_optimize
MODEL_ID = "models/VoxCPM-0.5B"
ZIPENHANCER_MODEL_ID = "models/speech_zipenhancer_ans_multiloss_16k_base"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

_model: Optional[VoxCPM] = None


def get_model() -> VoxCPM:
    """Lazily initialize and cache the VoxCPM pipeline."""
    global _model
    if _model is None:
        _model = VoxCPM.from_pretrained(
            hf_model_id=MODEL_ID,
            load_denoiser=False,
            zipenhancer_model_id=ZIPENHANCER_MODEL_ID,
            local_files_only=True,
            device=DEVICE,
        )
    return _model


def _save_prompt_audio(prompt_audio: Tuple[int, np.ndarray]) -> Optional[str]:
    """Persist uploaded prompt audio to a temporary WAV file."""
    if prompt_audio is None:
        return None

    sample_rate, audio = prompt_audio
    if audio is None:
        return None

    if audio.ndim > 1:
        audio = audio.mean(axis=-1)
    audio = audio.astype(np.float32)

    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
        sf.write(tmp_file.name, audio, sample_rate)
        return tmp_file.name


def generate_speech(
    model_ready: bool,
    text: str,
    prompt_audio: Optional[Tuple[int, np.ndarray]],
    prompt_text: Optional[str],
    cfg_value: float,
    inference_timesteps: int,
    normalize: bool,
    denoise: bool,
    retry_badcase: bool,
    retry_badcase_max_times: int,
    retry_badcase_ratio_threshold: float,
):
    if not bool(model_ready):
        raise gr.Error("è¯·å…ˆç‚¹å‡»â€œåŠ è½½æ¨¡å‹â€æŒ‰é’®ã€‚")

    text = (text or "").strip()
    if not text:
        raise gr.Error("è¯·è¾“å…¥éœ€è¦åˆæˆçš„æ–‡æœ¬ã€‚")

    prompt_text = (prompt_text or "").strip()
    prompt_wav_path: Optional[str] = None
    temp_wav_path: Optional[str] = None

    try:
        if prompt_audio is not None:
            if not prompt_text:
                raise gr.Error("æä¾›æç¤ºéŸ³é¢‘æ—¶éœ€è¦åŒæ—¶å¡«å†™æç¤ºæ–‡æœ¬ã€‚")
            prompt_wav_path = _save_prompt_audio(prompt_audio)
            temp_wav_path = prompt_wav_path

        model = get_model()
        sample_rate = getattr(model.tts_model.audio_vae, "sample_rate", 16000)

        wav = model.generate(
            text=text,
            prompt_wav_path=prompt_wav_path,  # type: ignore
            prompt_text=prompt_text if prompt_wav_path else None,  # type: ignore
            cfg_value=cfg_value,
            inference_timesteps=inference_timesteps,
            normalize=normalize,
            denoise=denoise,
            retry_badcase=retry_badcase,
            retry_badcase_max_times=retry_badcase_max_times,
            retry_badcase_ratio_threshold=retry_badcase_ratio_threshold,
        )

        wav = np.asarray(wav, dtype=np.float32)
        return sample_rate, wav

    except Exception as exc:
        raise gr.Error(f"ç”Ÿæˆè¯­éŸ³å¤±è´¥ï¼š{exc}") from exc
    finally:
        if temp_wav_path:
            try:
                os.unlink(temp_wav_path)
            except OSError:
                pass


def load_model_action():
    try:
        model = get_model()
        sample_rate = getattr(model.tts_model.audio_vae, "sample_rate", 16000)
        device_info = "GPU (CUDA)" if DEVICE == "cuda" else "CPU"
        status_md = (
            f"**ğŸŸ¢ æ¨¡å‹çŠ¶æ€ï¼šå·²åŠ è½½**\n\n"
            f"- è®¾å¤‡ï¼š{device_info}\n"
            f"- é‡‡æ ·ç‡ï¼š{sample_rate} Hz\n"
            f"- æ¨¡å‹ï¼šVoxCPM-0.5B\n\n"
            f"âœ… å¯ä»¥å¼€å§‹ç”Ÿæˆè¯­éŸ³äº†ï¼"
        )
        return (
            status_md,
            True,
            gr.update(interactive=False, value="âœ… å·²åŠ è½½"),
            gr.update(interactive=True, variant="primary"),
        )
    except Exception as exc:
        error_md = (
            f"**ğŸ”´ æ¨¡å‹åŠ è½½å¤±è´¥**\n\n"
            f"é”™è¯¯ä¿¡æ¯ï¼š{str(exc)}\n\n"
            f"è¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨äº `{MODEL_ID}` ç›®å½•"
        )
        return (
            error_md,
            False,
            gr.update(interactive=True),
            gr.update(interactive=False),
        )


with gr.Blocks(title="VoxCPM è¯­éŸ³åˆæˆ") as demo:
    gr.Markdown(
        """
        # ğŸ™ï¸ VoxCPM è¯­éŸ³åˆæˆæ¼”ç¤º
        
        VoxCPM æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„é›¶æ ·æœ¬è¯­éŸ³åˆæˆæ¨¡å‹ï¼Œæ”¯æŒé«˜è´¨é‡çš„å£°éŸ³å…‹éš†å’Œå¤šè¯­è¨€åˆæˆã€‚
        """
    )

    model_loaded_state = gr.State(False)

    # å¿«é€Ÿå…¥é—¨æç¤º
    with gr.Accordion("ğŸ“– å¿«é€Ÿå…¥é—¨", open=False, elem_id="tips-accordion"):
        gr.Markdown(
            """
            ### ä½¿ç”¨æ­¥éª¤
            1. **åŠ è½½æ¨¡å‹** - ç‚¹å‡»"åŠ è½½æ¨¡å‹"æŒ‰é’®ï¼Œç­‰å¾…æ¨¡å‹åˆå§‹åŒ–å®Œæˆ
            2. **è¾“å…¥æ–‡æœ¬** - åœ¨æ–‡æœ¬æ¡†ä¸­è¾“å…¥éœ€è¦åˆæˆçš„å†…å®¹
            3. **ï¼ˆå¯é€‰ï¼‰å£°éŸ³å…‹éš†** - ä¸Šä¼ å‚è€ƒéŸ³é¢‘å’Œå¯¹åº”æ–‡æœ¬ï¼Œå®ç°å£°éŸ³å…‹éš†
            4. **ç”Ÿæˆè¯­éŸ³** - ç‚¹å‡»"ç”Ÿæˆè¯­éŸ³"æŒ‰é’®å¼€å§‹åˆæˆ
            
            ### ğŸ’¡ å‚æ•°è¯´æ˜
            - **CFG å€¼**ï¼šæ§åˆ¶å¯¹æç¤ºéŸ³é¢‘çš„éµå¾ªç¨‹åº¦ï¼ˆ1.0-4.0ï¼‰ï¼Œå€¼è¶Šé«˜è¶Šæ¥è¿‘å‚è€ƒéŸ³è‰²
            - **æ¨ç†æ­¥æ•°**ï¼šå½±å“ç”Ÿæˆè´¨é‡å’Œé€Ÿåº¦ï¼ˆ5-30æ­¥ï¼‰ï¼Œæ­¥æ•°è¶Šå¤šè´¨é‡è¶Šå¥½ä½†é€Ÿåº¦è¶Šæ…¢
            - **æ–‡æœ¬æ ‡å‡†åŒ–**ï¼šè‡ªåŠ¨å¤„ç†æ•°å­—ã€ç¬¦å·ç­‰ç‰¹æ®Šæ–‡æœ¬ï¼Œå…³é—­åæ”¯æŒéŸ³ç´ è¾“å…¥
            - **éŸ³é¢‘é™å™ª**ï¼šå¯¹å‚è€ƒéŸ³é¢‘è¿›è¡Œé™å™ªå¤„ç†ï¼Œæå‡å…‹éš†æ•ˆæœ
            """
        )

    with gr.Row():
        # å·¦ä¾§ï¼šè¾“å…¥æ§åˆ¶åŒº
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ“ æ–‡æœ¬è¾“å…¥")
            
            text_input = gr.Textbox(
                label="å¾…åˆæˆæ–‡æœ¬",
                lines=6,
                placeholder="è¯·è¾“å…¥éœ€è¦åˆæˆçš„æ–‡æœ¬å†…å®¹...",
                info="æ”¯æŒä¸­è‹±æ–‡æ··åˆè¾“å…¥ï¼Œå¯ä½¿ç”¨æ ‡ç‚¹ç¬¦å·æ§åˆ¶åœé¡¿",
            )

            gr.Markdown("### ğŸ¤ å£°éŸ³å…‹éš†ï¼ˆå¯é€‰ï¼‰")
            
            prompt_audio_input = gr.Audio(
                label="å‚è€ƒéŸ³é¢‘",
                type="numpy",
                sources=["upload", "microphone"],
            )
            
            prompt_text_input = gr.Textbox(
                label="å‚è€ƒæ–‡æœ¬",
                lines=2,
                placeholder="è¯·è¾“å…¥å‚è€ƒéŸ³é¢‘å¯¹åº”çš„æ–‡æœ¬å†…å®¹...",
                info="å‚è€ƒéŸ³é¢‘ä¸­è¯´è¯äººè¯´çš„å†…å®¹",
            )

            gr.Markdown("### âš™ï¸ ç”Ÿæˆå‚æ•°")
            
            with gr.Row():
                cfg_slider = gr.Slider(
                    minimum=0.5,
                    maximum=4.0,
                    step=0.1,
                    value=2.0,
                    label="CFG å¼•å¯¼å€¼",
                    info="æ¨èå€¼ï¼š2.0-2.5",
                )
                timestep_slider = gr.Slider(
                    minimum=5,
                    maximum=30,
                    step=1,
                    value=10,
                    label="æ¨ç†æ­¥æ•°",
                    info="æ¨èå€¼ï¼š10-15",
                )

            with gr.Row():
                normalize_checkbox = gr.Checkbox(
                    value=True,
                    label="æ–‡æœ¬æ ‡å‡†åŒ–",
                    info="å¤„ç†æ•°å­—ã€ç¬¦å·ç­‰",
                )
                denoise_checkbox = gr.Checkbox(
                    value=True,
                    label="éŸ³é¢‘é™å™ª",
                    info="æå‡å…‹éš†æ•ˆæœ",
                )

            # é«˜çº§é€‰é¡¹
            with gr.Accordion("ğŸ”§ é«˜çº§é€‰é¡¹", open=False):
                retry_checkbox = gr.Checkbox(
                    value=True,
                    label="å¯ç”¨è‡ªåŠ¨é‡è¯•",
                    info="æ£€æµ‹åˆ°ç”Ÿæˆå¼‚å¸¸æ—¶è‡ªåŠ¨é‡è¯•",
                )
                
                with gr.Row():
                    retry_max_slider = gr.Slider(
                        minimum=1,
                        maximum=5,
                        step=1,
                        value=3,
                        label="æœ€å¤§é‡è¯•æ¬¡æ•°",
                    )
                    ratio_slider = gr.Slider(
                        minimum=1.0,
                        maximum=10.0,
                        step=0.5,
                        value=6.0,
                        label="éŸ³é¢‘é•¿åº¦é˜ˆå€¼ï¼ˆå€ï¼‰",
                        info="éŸ³é¢‘/æ–‡æœ¬é•¿åº¦æ¯”ä¾‹ä¸Šé™",
                    )

            # æ“ä½œæŒ‰é’®
            with gr.Row():
                load_button = gr.Button(
                    "ğŸš€ åŠ è½½æ¨¡å‹",
                    variant="primary",
                    scale=1,
                )
                generate_button = gr.Button(
                    "ğŸµ ç”Ÿæˆè¯­éŸ³",
                    interactive=False,
                    variant="secondary",
                    scale=1,
                )

        # å³ä¾§ï¼šè¾“å‡ºå±•ç¤ºåŒº
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ“Š çŠ¶æ€ä¿¡æ¯")
            
            model_status = gr.Markdown(
                "**ğŸ”´ æ¨¡å‹çŠ¶æ€ï¼šæœªåŠ è½½** - è¯·å…ˆç‚¹å‡»åŠ è½½æ¨¡å‹æŒ‰é’®",
            )

            gr.Markdown("### ğŸ”Š ç”Ÿæˆç»“æœ")
            
            output_audio = gr.Audio(
                label="åˆæˆéŸ³é¢‘",
                type="numpy",
                show_download_button=True,
                autoplay=False,
            )

            # ç¤ºä¾‹æ–‡æœ¬
            gr.Markdown("### ğŸ“š ç¤ºä¾‹æ–‡æœ¬")
            gr.Examples(
                examples=[
                    ["ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨ VoxCPM è¯­éŸ³åˆæˆç³»ç»Ÿã€‚"],
                    ["å…«ç™¾æ ‡å…µå¥”åŒ—å¡ï¼Œç‚®å…µå¹¶æ’åŒ—è¾¹è·‘ã€‚"],
                    ["VoxCPM æ˜¯ä¸€ä¸ªå¼ºå¤§çš„ç«¯åˆ°ç«¯è¯­éŸ³åˆæˆæ¨¡å‹ï¼Œæ”¯æŒé›¶æ ·æœ¬å£°éŸ³å…‹éš†ã€‚"],
                    ["æ˜¥çœ ä¸è§‰æ™“ï¼Œå¤„å¤„é—»å•¼é¸Ÿã€‚å¤œæ¥é£é›¨å£°ï¼ŒèŠ±è½çŸ¥å¤šå°‘ã€‚"],
                ],
                inputs=text_input,
                label=None,
            )

            # ä½¿ç”¨æç¤º
            with gr.Accordion("ğŸ’¬ ä½¿ç”¨å»ºè®®", open=False):
                gr.Markdown(
                    """
                    **å£°éŸ³å…‹éš†æŠ€å·§**
                    - å‚è€ƒéŸ³é¢‘å»ºè®®æ—¶é•¿ï¼š3-10ç§’
                    - å‚è€ƒéŸ³é¢‘è´¨é‡ï¼šæ¸…æ™°ã€æ— èƒŒæ™¯å™ªéŸ³
                    - å‚è€ƒæ–‡æœ¬è¦å‡†ç¡®å¯¹åº”éŸ³é¢‘å†…å®¹
                    
                    **å‚æ•°è°ƒä¼˜å»ºè®®**
                    - CFG å€¼è¿‡é«˜ï¼šéŸ³è´¨å¯èƒ½ä¸‹é™ï¼Œå£°éŸ³è¿‡äºå¤¸å¼ 
                    - CFG å€¼è¿‡ä½ï¼šå¯èƒ½åç¦»å‚è€ƒéŸ³è‰²
                    - æ¨ç†æ­¥æ•°å¢åŠ ï¼šè´¨é‡æå‡ä½†é€Ÿåº¦å˜æ…¢
                    
                    **æ–‡æœ¬è¾“å…¥æç¤º**
                    - æ”¯æŒä¸­è‹±æ–‡æ··åˆ
                    - ä½¿ç”¨æ ‡ç‚¹ç¬¦å·æ§åˆ¶è¯­æ°”å’Œåœé¡¿
                    - å…³é—­æ ‡å‡†åŒ–å¯è¾“å…¥éŸ³ç´ ï¼ˆå¦‚ {ni3}{hao3}ï¼‰
                    """
                )

    # äº‹ä»¶ç»‘å®š
    load_button.click(
        fn=load_model_action,
        inputs=[],
        outputs=[model_status, model_loaded_state, load_button, generate_button],
    )

    generate_button.click(
        fn=generate_speech,
        inputs=[
            model_loaded_state,
            text_input,
            prompt_audio_input,
            prompt_text_input,
            cfg_slider,
            timestep_slider,
            normalize_checkbox,
            denoise_checkbox,
            retry_checkbox,
            retry_max_slider,
            ratio_slider,
        ],
        outputs=output_audio,
    )


if __name__ == "__main__":
    demo.queue(max_size=4).launch(server_name="0.0.0.0", share=False)
